# -*- coding: utf-8 -*-
"""SCF_Maximally_Faulty_cluster.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lpd_nB65hUy7yIV9pcEh5JdQmrtVECk2
"""

import jax
import jax.numpy as jnp
import numpy as np
#!pip install optax
import optax
#from jax.experimental import optimizers
from jax import grad, value_and_grad, custom_vjp, jit
#import matplotlib.pyplot as plt
from functools import partial
import itertools
import sys
#from google.colab import files
#import io

#!git clone https://github.com/QPG-MIT/meshes.git
import meshes as ms
from meshes.mesh import StructuredMeshNetwork
from meshes.crossing import Crossing, MZICrossing
from meshes.jax import dot
from meshes.configure import errcorr_local

run_index = int(sys.argv[1])

from collections import namedtuple
import tensorflow as tf
from tensorflow.keras.datasets import mnist

#MNIST pre-processing cell
def norm_inputs(inputs, feature_axis=1):
    return inputs / np.sqrt(np.sum(np.abs(inputs)**2, axis=1))[:, None] * np.sqrt(20)


ONNData = namedtuple('ONNData', ['x_train', 'y_train', 'y_train_ind', 'x_test', 'y_test', 'y_test_ind', 'units', 'num_classes'])


class MNISTDataProcessor:
    def __init__(self, fashion: bool=False):
        (self.x_train_raw, self.y_train), (self.x_test_raw, self.y_test) = fashion_mnist.load_data() if fashion else mnist.load_data()
        self.num_train = self.x_train_raw.shape[0]
        self.num_test = self.x_test_raw.shape[0]
        self.x_train_ft = np.fft.fftshift(np.fft.fft2(self.x_train_raw), axes=(1, 2))
        self.x_test_ft = np.fft.fftshift(np.fft.fft2(self.x_test_raw), axes=(1, 2))
        
    def fourier(self, freq_radius):
        min_r, max_r = 14 - freq_radius, 14 + freq_radius
        x_train_ft = self.x_train_ft[:, min_r:max_r, min_r:max_r]
        x_test_ft = self.x_test_ft[:, min_r:max_r, min_r:max_r]
        return ONNData(
            x_train=norm_inputs(x_train_ft.reshape((self.num_train, -1))).astype(np.complex64).T,
            #x_train=(x_train_ft.reshape((self.num_train, -1))).astype(np.complex64).T,
            y_train=np.eye(10)[self.y_train].T,
            y_train_ind=self.y_train.T,
            x_test=norm_inputs(x_test_ft.reshape((self.num_test, -1))).astype(np.complex64).T,
            #x_test=(x_test_ft.reshape((self.num_test, -1))).astype(np.complex64).T,
            y_test=np.eye(10)[self.y_test].T,
            y_test_ind=self.y_test.T,
            units=(2 * freq_radius)**2,
            num_classes=10
        )


n = 8

mnist_dp = MNISTDataProcessor()
data_N256 = mnist_dp.fourier(n)

data_train = data_N256.x_train
data_test = data_N256.x_test

'''100'''
num_batches = 100

x_train_data = np.transpose(np.split(np.transpose(data_train), num_batches), [0, 2, 1])
y_train_data = np.transpose(np.split(np.transpose(data_N256.y_train), num_batches), [0, 2, 1])
x_test_data = data_test
y_test_data = data_N256.y_test


x_train_tensors_8 = (np.array(x_train_data)) * 1.0
y_train_tensors_8 = (np.array(y_train_data))
x_test_tensors_8 = (np.array(x_test_data)) * 1.0
y_test_tensors_8 = (np.array(y_test_data))

splitting_error = [0.1, 0.1, 0.1, 0.1, 0.1]
err_level = 0.5 * np.arcsin(2 * splitting_error[run_index])

N = 256
U_init = ms.haar_mat(N)
SCF_layer_1 = ms.ButterflyNetwork(N = None, M = U_init)

phases_1 = SCF_layer_1.p_phase
alpha_errs = [2*err_level*np.ones(SCF_layer_1.n_cr)]
beta_errs = [np.zeros(SCF_layer_1.n_cr)]
p_splitter_errs = np.concatenate((alpha_errs, beta_errs), axis = 0).T
print (p_splitter_errs.shape)

SCF_layer_1 = ms.ButterflyNetwork(N = None, M = U_init, p_splitter = p_splitter_errs)
SCF_layer_2 = ms.ButterflyNetwork(N = None, M = U_init, p_splitter = p_splitter_errs)

def NN_linear_pass(mesh, phases, input_data):
  layer_out = dot(mesh, phases, input_data)
  return layer_out

def eo_nl(Z):
  return 1j * jnp.sqrt(1-0.1) * jnp.exp(-1j*0.5*0.05*jnp.pi*jnp.conj(Z)*Z - 1j*0.5*jnp.pi) * jnp.cos(0.5*0.05*jnp.pi*jnp.conj(Z)*Z + 0.5*jnp.pi) * Z

phases_1 = SCF_layer_1.p_phase
phases_2 = SCF_layer_2.p_phase

def loss_func(phases_1, phases_2, input_data, labels):
  layer_1_out = eo_nl(NN_linear_pass(SCF_layer_1, phases_1, input_data))
  NN_output = eo_nl(NN_linear_pass(SCF_layer_2, phases_2, layer_1_out))
  y_pred = jnp.abs(NN_output[:10, :])**2
  y_pred = y_pred/(jnp.sum(y_pred, axis = 0))
  loss_val = jnp.mean(jnp.abs(labels - (y_pred))**2)
  target_class = jnp.argmax(labels, axis = 0)
  predicted_class = jnp.argmax((y_pred), axis = 0)
  acc_val = jnp.mean(target_class == predicted_class)
  return loss_val, acc_val

num_epochs = 50
#exp_decay = optimizers.exponential_decay(0.01, num_batches * num_epochs, 0.02)
scheduler = optax.exponential_decay(init_value=0.01, transition_steps = num_batches * num_epochs, decay_rate=0.02)
#opt_init, opt_update, get_params = optimizers.adam(exp_decay)
optimizer = optax.adam(scheduler)


def update(step, phases_1, phases_2, opt_state, input_data, labels):
  (loss_val, acc_val), grads = value_and_grad(loss_func, (0, 1), has_aux = True)(phases_1, phases_2, input_data, labels)
  #opt_state = opt_update(step, grads, opt_state)
  updates, opt_state = optimizer.update(grads, opt_state)
  #phases_1, phases_2 = get_params(opt_state)
  phases_1, phases_2 = optax.apply_updates((phases_1, phases_2), updates)
  return loss_val, acc_val, opt_state, (phases_1, phases_2)

#opt_state = opt_init((phases_1, phases_2))
opt_state = optimizer.init((phases_1, phases_2))
loss_val, acc_val, opt_state, (phases_1, phases_2) = update(0, phases_1, phases_2, opt_state, x_train_tensors_8[0], y_train_tensors_8[0])
print (loss_val, acc_val)

loss_array = []
acc_array = []
itercount = itertools.count()

for epoch in range(num_epochs):
  #opt_state = opt_init((phases_1, phases_2))
  opt_state = optimizer.init((phases_1, phases_2))
  for _ in range(num_batches):
    loss_val, acc_val, opt_state, (phases_1, phases_2) = update(0, phases_1, phases_2, opt_state, x_train_tensors_8[_], y_train_tensors_8[_])
    #print (loss_val, acc_val)
  loss_val, acc_val = loss_func(phases_1, phases_2, x_test_tensors_8, y_test_tensors_8)
  acc_array.append(acc_val); loss_array.append(loss_val)
  print ("Epoch Number: " + str(epoch) + ", Loss: " + str(loss_val) + ", Accuracy: " + str(acc_val))


file_name = str('SCF_MF_phases_1_'+str(N)+'_err_'+str(splitting_error[run_index])+'_run_'+str(run_index)+'.npz')
phase_1_array = np.array(phases_1)
np.savez(file_name, p = phase_1_array)
file_name = str('SCF_MF_phases_2_'+str(N)+'_err_'+str(splitting_error[run_index])+'_run_'+str(run_index)+'.npz')
phase_2_array = np.array(phases_2)
np.savez(file_name, p = phase_2_array)